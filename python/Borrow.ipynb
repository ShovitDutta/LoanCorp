{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install optuna torch numpy pandas scikit-learn\n",
        "# %%\n",
        "import os\n",
        "import torch\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "xOFwkrvvzrh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a short summary of the model's progress and current status:\n",
        "\n",
        "* **Initial State (Poor):** Model performed very poorly with extremely high MSE (over 100 million to 2.8 billion) and scattered prediction plots, indicating no meaningful learning.\n",
        "* **Key Improvement:** Scaling the target variable (Borrowing Capacity) was introduced.\n",
        "* **Current State (Excellent):**\n",
        "    * **Drastic MSE Reduction:** Scaled MSE dropped to a very low value (e.g., $0.0035$), and the RMSE on the original scale is now a reasonable $\\text{\\textdollar}5251$.\n",
        "    * **Strong Predictive Power:** Plots show predictions tightly clustered around actual values, demonstrating a clear and accurate linear relationship.\n",
        "    * **Healthy Residuals:** Residuals are randomly distributed around zero, indicating no systematic errors.\n",
        "* **Conclusion:** The model is now performing effectively on the synthetic dataset."
      ],
      "metadata": {
        "id": "QAl20Zov4T46"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "import optuna\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "num_samples = 5000\n",
        "\n",
        "residence_types = [\"Own\", \"Rent\", \"Mortgage\"]\n",
        "marital_statuses = [\"Single\", \"Married\", \"Divorced\", \"Widowed\"]\n",
        "cities = [\"CityA\", \"CityB\", \"CityC\", \"CityD\", \"CityE\"]\n",
        "states = [\"State1\", \"State2\", \"State3\", \"State4\"]\n",
        "\n",
        "data = {\n",
        "    \"Residence_type\": np.random.choice(residence_types, num_samples),\n",
        "    \"Monthly_income\": np.random.normal(6000, 2000, num_samples).clip(2500, 20000),\n",
        "    \"Previous_loan\": np.random.randint(0, 3, num_samples),\n",
        "    \"Marital_Status\": np.random.choice(marital_statuses, num_samples),\n",
        "    \"Number_of_dependency\": np.random.randint(0, 7, num_samples),\n",
        "    \"Credit_Score\": np.random.normal(700, 50, num_samples).clip(500, 850),\n",
        "    \"Employment_Years\": np.random.normal(8, 4, num_samples).clip(0, 30),\n",
        "    \"City\": np.random.choice(cities, num_samples),\n",
        "    \"State\": np.random.choice(states, num_samples),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df['Borrowing_capacity'] = 20000 + (df['Monthly_income'] * 5)\n",
        "df['Borrowing_capacity'] += df['Residence_type'].map({'Own': 5000, 'Rent': -2000, 'Mortgage': 2000}).fillna(0)\n",
        "df['Borrowing_capacity'] += (df['Credit_Score'] - 600) * 50\n",
        "df['Borrowing_capacity'] += (df['Credit_Score'] - 700)**2 * 0.1\n",
        "df['Borrowing_capacity'] -= df['Previous_loan'] * 3000\n",
        "df['Borrowing_capacity'] += np.log1p(df['Employment_Years']) * 1000\n",
        "df['Borrowing_capacity'] -= df['Number_of_dependency'] * 1500\n",
        "df['Borrowing_capacity'] += np.random.normal(0, 5000, num_samples)\n",
        "df['Borrowing_capacity'] = df['Borrowing_capacity'].clip(10000, 150000)\n",
        "\n",
        "categorical_features = [\"Residence_type\", \"Marital_Status\", \"City\", \"State\"]\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.drop(\"Borrowing_capacity\", axis=1).values\n",
        "y = df[\"Borrowing_capacity\"].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_val = scaler_X.transform(X_val)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1))\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val_scaled, dtype=torch.float32)\n",
        "\n",
        "class BorrowingCapacityModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim1),\n",
        "            nn.BatchNorm1d(hidden_dim1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.BatchNorm1d(hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim2, hidden_dim3),\n",
        "            nn.BatchNorm1d(hidden_dim3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim3, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_with_early_stopping(model, optimizer, criterion, X_train, y_train, X_val, y_val, max_epochs, patience, trial=None, checkpoint_dir=\"checkpoints\"):\n",
        "    best_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=False)\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            best_model_state = model.state_dict()\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f\"best_model_trial_{trial.number if trial else 'final'}.pth\")\n",
        "            torch.save(best_model_state, checkpoint_path)\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= patience:\n",
        "            break\n",
        "\n",
        "        if trial:\n",
        "            trial.report(val_loss, epoch)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, best_loss.item()\n",
        "\n",
        "def objective(trial):\n",
        "    hidden_dim1 = trial.suggest_int(\"hidden_dim1\", 64, 256)\n",
        "    hidden_dim2 = trial.suggest_int(\"hidden_dim2\", 32, 128)\n",
        "    hidden_dim3 = trial.suggest_int(\"hidden_dim3\", 16, 64)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.4)\n",
        "    epochs = trial.suggest_int(\"epochs\", 1000, 3000)\n",
        "\n",
        "    input_dim = X_train_tensor.shape[1]\n",
        "    model = BorrowingCapacityModel(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    _, val_loss = train_with_early_stopping(model, optimizer, criterion, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, max_epochs=epochs, patience=75, trial=trial)\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Value: {study.best_trial.value}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "best_params = study.best_trial.params\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "final_model = BorrowingCapacityModel(input_dim, best_params[\"hidden_dim1\"], best_params[\"hidden_dim2\"], best_params[\"hidden_dim3\"], best_params[\"dropout_rate\"])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"lr\"])\n",
        "\n",
        "final_model, final_val_loss_scaled = train_with_early_stopping(final_model, optimizer, criterion, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, max_epochs=best_params[\"epochs\"], patience=75, checkpoint_dir=\"final_model_checkpoint\")\n",
        "\n",
        "final_model.eval()\n",
        "with torch.no_grad():\n",
        "    val_predictions_scaled = final_model(X_val_tensor).numpy()\n",
        "    val_predictions_original = scaler_y.inverse_transform(val_predictions_scaled)\n",
        "\n",
        "final_val_mse_original_scale = np.mean((y_val - val_predictions_original.flatten())**2)\n",
        "\n",
        "print(f\"\\nFinal Validation MSE (Scaled): {final_val_loss_scaled}\")\n",
        "print(f\"Final Validation MSE (Original Scale): {final_val_mse_original_scale}\")\n",
        "print(f\"Final Validation RMSE (Original Scale): {np.sqrt(final_val_mse_original_scale)}\")\n",
        "\n",
        "torch.save(final_model.state_dict(), \"final_borrowing_capacity_model_simplified.pth\")\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(y_val, val_predictions_original, alpha=0.6)\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "plt.xlabel(\"Actual Borrowing Capacity\")\n",
        "plt.ylabel(\"Predicted Borrowing Capacity\")\n",
        "plt.title(\"Actual vs. Predicted Borrowing Capacity (Simplified Model)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "residuals = y_val - val_predictions_original.flatten()\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(val_predictions_original, residuals, alpha=0.6)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel(\"Predicted Borrowing Capacity\")\n",
        "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
        "plt.title(\"Residual Plot (Simplified Model)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_3N0ZdOjz0F0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}